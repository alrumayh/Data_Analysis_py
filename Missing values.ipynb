{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc9d4d1",
   "metadata": {},
   "source": [
    "Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ece6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values could be represented as Nan, 0, or as an empty cell\n",
    "# there are different ways to handle missing values, we can delet the variable or replace it to what we think the data point is. but I am not gonna explain them all here. \n",
    "\n",
    "DF.dropna()# we can use this code and it will remove all missing values. \n",
    "\n",
    "#Or we can specified the axis = 0 > row; axis = 1 > column \n",
    "\n",
    "DF.dropna(moto = [\"column\"], axis = 0, inplace = True) # inplace = True will delete the missing value from the DF permenantly\n",
    "\n",
    "DF.dropna(moto = [\"column\"], axis = 0) #This will not modify the DF, it will only show you how DF will look like if you delete the NaN. \n",
    "\n",
    "DF.replace(column_old, column_new)\n",
    "\n",
    "# In case you want to replace the NaN with mean, you do this:\n",
    "\n",
    "m = DF[\"column\"].mean()\n",
    "DF[\"column\"].replace(np.nan, m)\n",
    "\n",
    "# To save the results to the dataframe \"drive_wheels_counts\" and rename the column 'drive-wheels' to 'value_counts'\n",
    "x_count = FD['col'].value_counts().to_frame()\n",
    "x_count.rename(columns={'col': 'col_new'}, inplace=True)\n",
    "x_count\n",
    "\n",
    "# This let you rename the index to col_new, \n",
    "x_count.index.name = 'col_new'\n",
    "x_count \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f9d90",
   "metadata": {},
   "source": [
    "Changing data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting data types \n",
    "#First look at the data type for each column \n",
    "\n",
    "DF.info()\n",
    "#Or\n",
    "DF.dtypes()\n",
    "\n",
    "#Now you can convert what you want to convert by using this: \n",
    "\n",
    "DF.astype()\n",
    "\n",
    "#For example: \n",
    "\n",
    "DF[\"column\"] = DF[\"column\"].astype(\"int\")\n",
    "#Or\n",
    "DF[\"column\"] = DF[\"column\"].astype(\"float\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fc53e",
   "metadata": {},
   "source": [
    "Data normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779919aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization is helpful to fix the range of your variables for later analyis\n",
    "\n",
    "# There are three types: i) Simple Feature scaling; ii) Min-Max; iii) Z-score\n",
    "\n",
    "# i: x(new) = x(old)/x(new)\n",
    "# ii: x(new) = x(old) - x(min) / x(max) - x(min)\n",
    "# iii: x(new) = x(old) - mu(average of the feature) / SD sigma > results range from -3 to +3\n",
    "\n",
    "DF[\"column\"] = DF[\"column\"] / DF[\"column\"].max()\n",
    "\n",
    "DF[\"column\"] = (DF[\"column\"] - DF[\"column\"].min())/\n",
    "               (DF[\"column\"].max() - DF[\"column\"].min()) \n",
    "\n",
    "DF[\"column\"] = (DF[\"column\"] - DF[\"column\"].mean()) / DF[\"column\"].std()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784027c7",
   "metadata": {},
   "source": [
    "Binning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a781cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning group values into bins (numerical to catagorical)\n",
    "\n",
    "bins = np.linspace(min(DF[\"column\"]), max(DF[\"column\"]), 4)\n",
    "\n",
    "group_n = [\"cold\", \"hot\", \"netural\"]\n",
    "\n",
    "DF[\"column-binned\"] = pd.cut(DF[\"column\"], bins, labels = group_n, include_lowest = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d8be9",
   "metadata": {},
   "source": [
    "Categorical var to numerical var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On-hot encoding: create a new column for each variable and convert them into 0 & 1\n",
    "# For example if you have a column with two possible var such as normal or abnormal, you will create one column for normal (1 x N matrix) and another column for abnormal (1:0)\n",
    "\n",
    "pd.get_dummies(DF[\"column\"])\n",
    "\n",
    "# DF[\"column\"] = DF[\"column\"].cat.codes\n",
    "\n",
    "# DF['column'] = [DF.cat.column.to_list()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae25f0cd",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "\n",
    "* Descriptive stat\n",
    "* GroupBy\n",
    "* Correlation \n",
    "* Correlation - stat (person correlation & heat maps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c541a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default setting of \"describe\" skips variables of type object. We can apply the method \"describe\" on the variables of type 'object' as follows\n",
    "DF.describe(include=['object'])\n",
    "\n",
    "DF['column'].value_counts().to_frame() # place it in  a frame\n",
    "\n",
    "# Box Plots shows the median (middle of the box), upper quartile (top of the box); lower quartile (..); upper and lower extreme (end-line of the guided line)\n",
    "\n",
    "sns.boxplt(x = \"column1\", y = \"column2\", data=DF)\n",
    "\n",
    "# Scatter plot shows point-like representation of your data to see the relationship between 2 var\n",
    "# y = axis > target/dependant var; x axis > predictor/independant var\n",
    "# e.g., price (y axis) and device_type (x axis)\n",
    "# Suitable for Continuous Numerical Variables\n",
    "\n",
    "y = DF[\"price\"]\n",
    "x = DF [\"device_type\"]\n",
    "plt.scatter(x, y)\n",
    "plt.ylabel(\"price\") #label y \n",
    "\n",
    "\n",
    "sns.regplot(x=\"device_type\", y = \"price\", data = DF)\n",
    "plt.ylim(0, ) #wil draw a line over your dots\n",
    "\n",
    "\n",
    "# suitable for categorical var plotted against continous var\n",
    "sns.boxplot(x=\"columnx\", y=\"columny\", data=DF)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a98b06",
   "metadata": {},
   "source": [
    "GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to group your data; can be applied on categorical var; single or multiple var.\n",
    "\n",
    "test = DF[[\"column1\", \"column2\", \"column3\"]]\n",
    "test1 = test.groupby([\"column1\", \"column2\"], as_index = False).mean() #this will organize your column based on col1 and col2 (e.g., col1 x > col1 y > col1 z)\n",
    "# You can also group different columns by other ways not noly mean\n",
    "# Or\n",
    "testt = df[['col1','col2']].groupby(['col2'],as_index= False).mean() # this will show you the mean of each elements of col2 and its mean with col1 (show you only 5 var)\n",
    "\n",
    "\n",
    "\n",
    "#Heatmap \n",
    "\n",
    "plt.pcolor(DF_pivot, cmap = \"RdBu\") #RdBu > Red Blue\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3343c",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To measure the strength of the correlation between 2 continuous numerical var\n",
    "# Pearson correlation : gives you i) correlation coefficient; ii) P value\n",
    "## method{‘pearson’, ‘kendall’, ‘spearman’} or callable\n",
    "# Correlation is the measure of the linear relationship between the two variables. \n",
    "# This method computes the pairwise correlation of columns, excluding NA/null values. It returns correlation matrix DataFrame\n",
    "\n",
    "# pearson : standard correlation coefficient\n",
    "# kendall : Kendall Tau correlation coefficient\n",
    "# spearman : Spearman rank correlation\n",
    "# The output of the methods is between 1 and -1.\n",
    "        # 1 indicates a strong positive relationship.\n",
    "        # -1 indicates a strong negative relationship.\n",
    "        # A result of zero indicates no relationship at all.\n",
    "\n",
    "print(df.corr(method='pearson'))\n",
    "# or\n",
    "pearson_coef, p_value = stats.pearsoner(DF[\"column\"], DF[\"column2\"])\n",
    "\n",
    "\n",
    "print(df.corr(method='kendall'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6b8ee",
   "metadata": {},
   "source": [
    "Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc82dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Analysis of Variance (ANOVA) is a statistical method used to test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:\n",
    "\n",
    "# F-test score: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.\n",
    "\n",
    "# P-value: P-value tells how statistically significant our calculated score value is.\n",
    "\n",
    "# If our column variable is strongly correlated with the variable we are analyzing, we expect ANOVA to return a sizeable F-test score and a small p-value\n",
    "\n",
    "\n",
    "gptest = fd[[\"BM\", \"ee\"]]\n",
    "\n",
    "grouped_test2 =gptest[['BM', 'ee']].groupby(['BM'])\n",
    "grouped_test2.head(2)\n",
    "grouped_test2.get_group('N')['ee']\n",
    "# ANOVA\n",
    "f_val, p_val = stats.f_oneway(grouped_test2.get_group('N')['ee'], grouped_test2.get_group('O')['ee'], grouped_test2.get_group('OV')['echo_lvef_percentage'], grouped_test2.get_group('VO')['ee'], grouped_test2.get_group('OV1')['ee'])  \n",
    " \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57144c",
   "metadata": {},
   "source": [
    "Chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b31477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Chi-square tests a null hypothesis that the variables are independen\n",
    "# Used for two categorical vars\n",
    "\n",
    "scipy.stats.chi2_contingency(cont_table, correction = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
